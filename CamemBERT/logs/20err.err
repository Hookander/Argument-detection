Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert/camembert-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'roberta.embeddings.word_embeddings.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
wandb: Currently logged in as: balthazar-martin123. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.4
wandb: Run data is saved locally in ./wandb/run-20240415_214521-e5wo8g4a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-darkness-13
wandb: â­ï¸ View project at https://wandb.ai/balthazar-martin123/camembert_dom
wandb: ğŸš€ View run at https://wandb.ai/balthazar-martin123/camembert_dom/runs/e5wo8g4a
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-SXM4-80GB MIG 2g.20gb') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type                               | Params
-------------------------------------------------------------
0 | model | CamembertForSequenceClassification | 336 M 
-------------------------------------------------------------
336 M     Trainable params
0         Non-trainable params
336 M     Total params
1,346.732 Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/raid/home/automatants/martin_bal/PoleProj/Argument-detection/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.
/raid/home/automatants/martin_bal/PoleProj/Argument-detection/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.
/raid/home/automatants/martin_bal/PoleProj/Argument-detection/.venv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
slurmstepd: error: *** JOB 7930 ON dgxa100 CANCELLED AT 2024-04-15T21:45:29 ***
wandb: - 0.015 MB of 0.015 MB uploadedwandb: \ 0.015 MB of 0.015 MB uploadedwandb: | 0.015 MB of 0.015 MB uploadedwandb: / 0.018 MB of 0.023 MB uploaded (0.002 MB deduped)wandb: - 0.023 MB of 0.023 MB uploaded (0.002 MB deduped)wandb: 
wandb: Run history:
wandb:               epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:          train/loss â–ˆâ–‡â–‡â–‡â–†â–†â–…â–…â–„â–…â–ƒâ–‚â–
wandb: trainer/global_step â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:           valid/acc â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‚â–ƒâ–ƒâ–ƒâ–„â–â–ƒâ–ƒâ–ƒâ–‚â–…â–ƒâ–…â–„â–…â–„â–…â–…â–ƒâ–…â–†â–ƒâ–†â–…â–„â–…â–„â–†â–„â–„â–…
wandb:            valid/f1 â–…â–…â–…â–…â–…â–…â–„â–…â–„â–â–ƒâ–ƒâ–„â–„â–â–†â–…â–ƒâ–„â–ˆâ–‚â–ˆâ–†â–ˆâ–‡â–‡â–†â–…â–†â–‡â–ƒâ–…â–…â–„â–ƒâ–†â–†â–„â–ƒâ–…
wandb: 
wandb: Run summary:
wandb:               epoch 50
wandb:          train/loss 0.26845
wandb: trainer/global_step 662
wandb:           valid/acc 0.17708
wandb:            valid/f1 0.07282
wandb: 
wandb: ğŸš€ View run sparkling-darkness-13 at: https://wandb.ai/balthazar-martin123/camembert_dom/runs/e5wo8g4a
wandb: ï¸âš¡ View job at https://wandb.ai/balthazar-martin123/camembert_dom/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE2MjMxMjUwMg==/version_details/v2
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240415_214521-e5wo8g4a/logs
wandb: - 0.015 MB of 0.018 MB uploadedwandb: \ 0.019 MB of 0.019 MB uploadedwandb: 
wandb: Run history:
wandb:               epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:          train/loss â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–†â–ˆâ–†â–‡â–†â–†â–†â–‡â–„â–…â–†â–„â–ˆâ–…â–„â–„â–…â–â–‚â–â–‚â–â–‚â–â–‚â–â–ƒâ–„â–â–â–â–â–â–‚
wandb: trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:           valid/acc â–ˆâ–ˆâ–†â–ˆâ–ˆâ–‡â–‡â–‡â–„â–‡â–…â–‚â–†â–ƒâ–†â–ˆâ–‚â–ƒâ–ƒâ–„â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–â–‚
wandb:            valid/f1 â–ˆâ–ˆâ–†â–ˆâ–ˆâ–†â–‡â–‡â–…â–‡â–…â–‚â–†â–„â–…â–ˆâ–‚â–ƒâ–ƒâ–„â–‚â–â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–‚â–â–‚â–‚â–â–‚
wandb: 
wandb: Run summary:
wandb:               epoch 81
wandb:          train/loss 0.31524
wandb: trainer/global_step 8035
wandb:           valid/acc 0.11458
wandb:            valid/f1 0.06076
wandb: 
wandb: ğŸš€ View run good-galaxy-11 at: https://wandb.ai/balthazar-martin123/camembert_dom/runs/hyxjhq7d
wandb: ï¸âš¡ View job at https://wandb.ai/balthazar-martin123/camembert_dom/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE2MjMxMjUwMg==/version_details/v3
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240415_214122-hyxjhq7d/logs
